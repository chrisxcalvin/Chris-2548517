{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "stiGVeaddEFV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "e-2dGjOae3lq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJInqHmGe4w_",
        "outputId": "1e2983c5-03a4-4f02-e1c6-070a86ca2887"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 116MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 4.08MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 60.7MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "IRy-A8Nkf6Vv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "j1jvrnG_f8oC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionNet()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "PgM1snUigmvD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV7wuR4egq9F",
        "outputId": "0c14055d-124d-43ad-b9e6-77da106e1a2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 206.4493, Accuracy: 91.74%\n",
            "Epoch [2/10] Loss: 196.2805, Accuracy: 91.99%\n",
            "Epoch [3/10] Loss: 189.1189, Accuracy: 92.33%\n",
            "Epoch [4/10] Loss: 178.6643, Accuracy: 92.77%\n",
            "Epoch [5/10] Loss: 174.5890, Accuracy: 93.01%\n",
            "Epoch [6/10] Loss: 166.8051, Accuracy: 93.31%\n",
            "Epoch [7/10] Loss: 160.6346, Accuracy: 93.42%\n",
            "Epoch [8/10] Loss: 154.4364, Accuracy: 93.70%\n",
            "Epoch [9/10] Loss: 150.0976, Accuracy: 93.88%\n",
            "Epoch [10/10] Loss: 142.5705, Accuracy: 94.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFiwX9sjjsBG",
        "outputId": "ddf239db-6f1d-4693-c201-3a801488e6a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LESQXMFHk2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimised Version:\n"
      ],
      "metadata": {
        "id": "MSzk4XJqk28o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OptimizedFashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "phLzIkz7k6zS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Change\t-             Effect)\n",
        "(Fewer layers\t -     Less overfitting)\n",
        "(Dropout\t        -     Reduces variance)\n",
        "(Smaller network\t   -   Better bias-variance balance)"
      ],
      "metadata": {
        "id": "hxzatCYMlCAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = OptimizedFashionNet()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "I0tj5Db8lh2G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # training mode (important for Dropout)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Track accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "          f\"Loss: {avg_loss:.4f} \"\n",
        "          f\"Train Accuracy: {train_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-14wSG-6lkEO",
        "outputId": "8467fdfe-a097-44dc-aa03-9fdf5d737629"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.5692 Train Accuracy: 79.28%\n",
            "Epoch [2/10] Loss: 0.4325 Train Accuracy: 84.35%\n",
            "Epoch [3/10] Loss: 0.3999 Train Accuracy: 85.55%\n",
            "Epoch [4/10] Loss: 0.3766 Train Accuracy: 86.33%\n",
            "Epoch [5/10] Loss: 0.3628 Train Accuracy: 86.81%\n",
            "Epoch [6/10] Loss: 0.3494 Train Accuracy: 87.15%\n",
            "Epoch [7/10] Loss: 0.3379 Train Accuracy: 87.60%\n",
            "Epoch [8/10] Loss: 0.3313 Train Accuracy: 87.72%\n",
            "Epoch [9/10] Loss: 0.3251 Train Accuracy: 87.97%\n",
            "Epoch [10/10] Loss: 0.3159 Train Accuracy: 88.51%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # evaluation mode (Dropout OFF)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # no gradient computation\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB5e_yG2oFW8",
        "outputId": "5444af62-dd3f-4840-a924-0222199c1ede"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this experiment, I built and trained a deep neural network to classify Fashion MNIST images using PyTorch. First, a larger model was trained to learn image features, and then the model was optimized by reducing layers and adding regularization to improve generalization. This showed that optimization helps make the model more stable and perfo\n",
        "rm better on new, unseen data."
      ],
      "metadata": {
        "id": "tCGTwBRVsIA8"
      }
    }
  ]
}